{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "You do not have to follow our installation instructions if you have roughly equivalent setups / environments already.\n",
    "\n",
    "We will use Conda and Pip to help us install packages for this homework. If you do not have Miniconda or Anaconda, you can install Miniconda from here https://docs.conda.io/en/latest/miniconda.html.\n",
    "\n",
    "```\n",
    "conda create --name exercise2 python=3.7\n",
    "conda activate exercise2\n",
    "\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "Go to https://pytorch.org/ to install PyTorch if you don't have it already\n",
    "\n",
    "To install the Hugging Face `transformers` library, run\n",
    "```\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "Follow the instructions from https://docs.dgl.ai/en/0.4.x/install/ to install Deep Graph Library (DGL).\n",
    "\n",
    "Spin up jupyter notebook with\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "# Overview\n",
    "Here we illustrate components of the paper [Graph-to-Tree Learning for Solving Math Word Problems](https://www.aclweb.org/anthology/2020.acl-main.362.pdf), which solves math word problems in the MAWPS dataset. The overall pipeline looks like this (note that we replaced the BiLSTM base model in the paper with a transformer base model):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/workflow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T03:09:19.236221Z",
     "start_time": "2020-10-29T03:09:19.201842Z"
    }
   },
   "source": [
    "# `util.setup`: Input Processing\n",
    "The `util.setup` function runs the preprocessing pipeline: loading in the dataset, parsing the dataset, building the vocabulary used for the models, converting the infix equation notation to prefix notation, and (if we're using T5) converting the word-level tokenization to byte-pair tokenization. We will illustrate the details here.\n",
    "\n",
    "## Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:47:57.361943Z",
     "start_time": "2020-10-29T20:47:57.356457Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from util import *\n",
    "\n",
    "path = 'data/mawps.json' # Path to the dataset\n",
    "n_min_vocab = 5\n",
    "seed = 0\n",
    "test_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:48:03.986479Z",
     "start_time": "2020-10-29T20:48:03.953749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2373\n"
     ]
    }
   ],
   "source": [
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:48:21.675042Z",
     "start_time": "2020-10-29T20:48:21.668334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expression': '(7.0*(7.0+2.0))',\n",
       " 'quant_cell_positions': [1, 2, 3, 9, 10, 11, 20, 21, 22, 28, 29, 30],\n",
       " 'processed_question': 'There were 7 friends playing a video game online when 2 more players joined the game . If each player had 7 lives , how many lives did they have total ?',\n",
       " 'raw_question': ' There were 7 friends playing a video game online when 2 more players joined the game. If each player had 7 lives, how many lives did they have total? ',\n",
       " 'is_quadratic': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[111]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the `2373` questions in the dataset consists of the following five fields\n",
    "1. `raw_question` is the original question.\n",
    "2. `processed_question` is a processed version of the question. Each word, quantity, or punctuation is separated by a space.\n",
    "3. `expression` is the desired output of the model. For the training set, this is the target. For the test set, this is compared with the prediction to score the prediction.\n",
    "4. `quant_cell_positions` is a list of positions in the text corresponding to quantity cells (quantities or associated nouns, adjectives, or verbs). We provide an illustration below and you can see the paper for more detail.\n",
    "5. `is_quadratic` is a flag denoting whether the problem requires solving a quadratic equation. This method cannot handle quadratics, so we discard the quadratic problems from the training set and count them as incorrect predictions for the test set. See below for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:51:57.056193Z",
     "start_time": "2020-10-29T07:51:57.047596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  There were 7 friends playing a video game online when 2 more players joined the game. If each player had 7 lives, how many lives did they have total? \n",
      "\n",
      "All tokens: ['There' 'were' '7' 'friends' 'playing' 'a' 'video' 'game' 'online' 'when'\n",
      " '2' 'more' 'players' 'joined' 'the' 'game' '.' 'If' 'each' 'player' 'had'\n",
      " '7' 'lives' ',' 'how' 'many' 'lives' 'did' 'they' 'have' 'total' '?']\n",
      "\n",
      "Quantity cell positions: [1, 2, 3, 9, 10, 11, 20, 21, 22, 28, 29, 30]\n",
      "\n",
      "Quantity cell tokens: ['were' '7' 'friends' 'when' '2' 'more' 'had' '7' 'lives' 'they' 'have'\n",
      " 'total']\n"
     ]
    }
   ],
   "source": [
    "d = data[111]\n",
    "tokens = np.array(d['processed_question'].split(' '))\n",
    "print('Question:', d['raw_question'])\n",
    "print()\n",
    "print('All tokens:', tokens)\n",
    "print()\n",
    "print('Quantity cell positions:', d['quant_cell_positions'])\n",
    "print()\n",
    "print('Quantity cell tokens:', tokens[d['quant_cell_positions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a question which requires solving the quadratic equation. We don't attempt to predict these questions and simply mark them as incorrect. Fortunately there are not very many quadratic questions in the MAWPS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:00.238797Z",
     "start_time": "2020-10-29T07:52:00.231090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: A blimp flies at 60 miles per hour. A round trip of 40 miles into the wind and 40 miles with the wind takes 1.5 hours. What is the speed of the wind , in miles per hour? \n",
      "\n",
      "Equation: (40.0/(60.0+x))+(40.0/(60.0-x))=1.5\n"
     ]
    }
   ],
   "source": [
    "d_quad = [d for d in data if d['is_quadratic']][0]\n",
    "print('Question:', d_quad['raw_question'])\n",
    "print()\n",
    "print('Equation:', d_quad['expression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:02.428337Z",
     "start_time": "2020-10-29T07:52:02.205509Z"
    }
   },
   "outputs": [],
   "source": [
    "constants, n_max_nP = tokenize_and_separate_quants(data, n_min_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize the `processed_question` field by splitting on the spaces. We replace the quantities in the tokens by the word `'NUM'`. We put the quantities into a list called `d['nP']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:02.941827Z",
     "start_time": "2020-10-29T07:52:02.935927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens with NUM: ['There', 'were', 'NUM', 'friends', 'playing', 'a', 'video', 'game', 'online', 'when', 'NUM', 'more', 'players', 'joined', 'the', 'game', '.', 'If', 'each', 'player', 'had', 'NUM', 'lives', ',', 'how', 'many', 'lives', 'did', 'they', 'have', 'total', '?']\n",
      "\n",
      "Quantities (nP) in the input: ['7' '2' '7']\n"
     ]
    }
   ],
   "source": [
    "d = data[111]\n",
    "print('Tokens with NUM:', d['in_tokens'])\n",
    "print()\n",
    "print('Quantities (nP) in the input:', d['nP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize the `expression` field into operators and quantities. Note that if the quantity is found in `d['nP']`, we replace the quantity by a tuple containing its matching indices in `d['nP']`. In the example below, `7.0` corresponds to indices `0` and `2` in `d['nP']`, while `2.0` corresponds to index `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:04.051846Z",
     "start_time": "2020-10-29T07:52:04.045846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: (7.0*(7.0+2.0))\n",
      "\n",
      "Out tokens: ['(', (0, 2), '*', '(', (0, 2), '+', (1,), ')', ')']\n"
     ]
    }
   ],
   "source": [
    "print('Expression:', d['expression'])\n",
    "print()\n",
    "print('Out tokens:', d['out_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the quantities that appears in the output of a question but not the input, we denote these as \"constants\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:31.887362Z",
     "start_time": "2020-10-29T07:52:31.883358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.01', '12', '1', '0.25', '100', '4', '0.5', '0.1', '3', '2', '7']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times constants represent some implicit quantity. For example, `'0.01'` is a constant below. It appears in the output expression because it corresponds to the \"%\" sign in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:32.294835Z",
     "start_time": "2020-10-29T07:52:32.287952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: You deposit 70 dollars in a savings account that pays an annual interest rate of 3 % . How much simple interest would you earn in 2.5 years , in dollars ?\n",
      "\n",
      "Expression: 70.0*2.5*3.0*0.01\n",
      "\n",
      "Out tokens: [(0,), '*', (2,), '*', (1,), '*', '0.01']\n"
     ]
    }
   ],
   "source": [
    "d = data[6]\n",
    "print('Question:', d['processed_question'])\n",
    "print()\n",
    "print('Expression:', d['expression'])\n",
    "print()\n",
    "print('Out tokens:', d['out_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:32.858048Z",
     "start_time": "2020-10-29T07:52:32.851540Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "np.random.shuffle(data)\n",
    "n_test = int(test_split * len(data))\n",
    "train_data, test_data = data[:-n_test], data[-n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T06:50:43.181890Z",
     "start_time": "2020-10-29T06:50:35.048Z"
    }
   },
   "source": [
    "## Building Input and Output Vocab\n",
    "We replace any token with fewer than `n_min_vocab` occurances in the dataset with the `<unk>` token. We build the input vocab from all the `in_tokens` in the training set along with the `<unk>` and `<pad>` tokens. The output vocab consists of the operator tokens, constants, and tokens denoting indices in `d['nP']` (we'll explain more on this shortly), along with the `<unk>` and `<pad>` tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:33.288852Z",
     "start_time": "2020-10-29T07:52:33.260219Z"
    }
   },
   "outputs": [],
   "source": [
    "default_tokens = ['<pad>', '<unk>']\n",
    "operation_tokens = ['+', '-', '*', '/']\n",
    "\n",
    "in_counts = Counter()\n",
    "for d in train_data:\n",
    "    in_counts.update(d['in_tokens'])\n",
    "in_vocab = Vocabulary([w for w, c in in_counts.items() if c >= n_min_vocab] + default_tokens)\n",
    "\n",
    "out_vocab = Vocabulary(operation_tokens + constants + [(i,) for i in range(n_max_nP)] + default_tokens)\n",
    "out_vocab.constants = constants\n",
    "out_vocab.n_constants = len(constants)\n",
    "out_vocab.n_ops = len(operation_tokens)\n",
    "out_vocab.base_op = 0\n",
    "out_vocab.base_quant = out_vocab.base_constant = out_vocab.base_op + out_vocab.n_ops\n",
    "out_vocab.base_nP = out_vocab.base_constant + out_vocab.n_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:33.566402Z",
     "start_time": "2020-10-29T07:52:33.544788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', '-', '*', '/', '0.01', '12', '1', '0.25', '100', '4', '0.5', '0.1', '3', '2', '7', (0,), (1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), '<pad>', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "print(out_vocab.idx2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `(0,)`, `(1,)`, `(2,)`, `(3,)`, `(4,)`, `(5,)`, `(6,)`, `(7,)`, and `(8,)` appear in `out_vocab`. These are actually very important for the tree decoding process for generating the output. Imagine if your input contained a quantity `1.324`; this quantity would be very rarely seen, so it doesn't make sense to add it as a constant (adding a lot of constants would make our vocab very large in size, which leads to overfitting). However, if `1.324` is the fifth quantity in the question, our model can predict `(4,)`, which represents the fifth quantity token in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Infix to Prefix Notation\n",
    "If you're not familiar with prefix notation, you can read more about it [here](http://www.cs.man.ac.uk/~pjj/cs212/fix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:52:34.217705Z",
     "start_time": "2020-10-29T07:52:34.212345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infix notation: [(0, 2), '+', (1,), '+', (0, 2)]\n",
      "\n",
      "Prefix notation: ['+', '+', (0, 2), (1,), (0, 2)]\n"
     ]
    }
   ],
   "source": [
    "d = data[10]\n",
    "print('Infix notation:', d['out_tokens'])\n",
    "print()\n",
    "print('Prefix notation:', infix_to_prefix(d['out_tokens']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Word-level Tokens to Byte-pair Tokens for T5\n",
    "If we are using the T5 model (and not the custom `TransformerBlock` layers), we must take an additional step to use the same tokenization that the pre-trained T5 model uses. This is pretty tricky since we also have to convert the positions of the numerical tokens from the old tokenization to the new tokenization scheme, but we have written a function to make the conversion. The input vocabulary will also be the same vocab that T5 uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:53:03.887007Z",
     "start_time": "2020-10-29T07:52:34.598167Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "use_t5 = 'small'\n",
    "from transformers import T5Tokenizer, T5Model\n",
    "# https://arxiv.org/pdf/1910.10683.pdf\n",
    "# https://huggingface.co/transformers/model_doc/t5.html\n",
    "# https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_t5.py\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(f't5-{use_t5}')\n",
    "t5_model = T5Model.from_pretrained(f't5-{use_t5}')\n",
    "in_vocab = Vocabulary(\n",
    "    [k for k, v in sorted(t5_tokenizer.get_vocab().items(), key=lambda k: k[1])],\n",
    "    t5_tokenizer.pad_token,\n",
    "    t5_tokenizer.unk_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:53:03.897675Z",
     "start_time": "2020-10-29T07:53:03.889221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw question:  Mrs. Hilt measured the distance from her desk to the water fountain. It was 30 feet. How many feet will Mrs. Hilt walk on her trips to the  fountain if she goes to the water fountain 4 times today?\n",
      "\n",
      "Word-level tokens: ['Mrs.', 'Hilt', 'measured', 'the', 'distance', 'from', 'her', 'desk', 'to', 'the', 'water', 'fountain', '.', 'It', 'was', 'NUM', 'feet', '.', 'How', 'many', 'feet', 'will', 'Mrs.', 'Hilt', 'walk', 'on', 'her', 'trips', 'to', 'the', '', '', 'fountain', 'if', 'she', 'goes', 'to', 'the', 'water', 'fountain', 'NUM', 'times', 'today', '?']\n",
      "Word-level quantity positions: [15 40]\n",
      "Word-level quantity cell positions: [14, 15, 16, 39, 40, 41, 40, 41, 42]\n",
      "\n",
      "T5 byte-pair tokens: ['Mrs', '.', 'Hil', 't', 'measured', 'the', 'distance', 'from', 'her', 'desk', 'to', 'the', 'water', 'fountain', '.', 'It', 'was', '30', 'feet', '.', 'How', 'many', 'feet', 'will', 'Mrs', '.', 'Hil', 't', 'walk', 'on', 'her', 'trips', 'to', 'the', 'fountain', 'if', 'she', 'goes', 'to', 'the', 'water', 'fountain', '4', 'times', 'today', '?']\n",
      "T5 byte-pair quantity positions: [17, 42]\n",
      "T5 byte-pair quantity cell positions: [16, 17, 18, 41, 42, 43, 42, 43, 44]\n"
     ]
    }
   ],
   "source": [
    "d = data[105]\n",
    "print('Raw question:', d['raw_question'])\n",
    "print()\n",
    "print('Word-level tokens:', d['in_tokens'])\n",
    "print('Word-level quantity positions:', d['nP_positions'])\n",
    "print('Word-level quantity cell positions:', d['quant_cell_positions'])\n",
    "print()\n",
    "d_t5 = d.copy()\n",
    "convert_word_to_bytepair_tokenization(d_t5, t5_tokenizer)\n",
    "print('T5 byte-pair tokens:', d_t5['in_tokens'])\n",
    "print('T5 byte-pair quantity positions:', d_t5['nP_positions'])\n",
    "print('T5 byte-pair quantity cell positions:', d_t5['quant_cell_positions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the quantity and quantity cell positions shifted slightly in the new tokenization scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `util.check_match`: Output Processing\n",
    "Output processing is used in `util.check_match`, which evaluates predicted tokens against the ground-truth tokens. We will walk through an example of output processing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:23:19.309645Z",
     "start_time": "2020-10-29T08:23:19.301410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw question:  Mrs. Hilt measured the distance from her desk to the water fountain. It was 30 feet. How many feet will Mrs. Hilt walk on her trips to the  fountain if she goes to the water fountain 4 times today?\n",
      "\n",
      "nP: ['30' '4']\n"
     ]
    }
   ],
   "source": [
    "d = data[105]\n",
    "print('Raw question:', d['raw_question'])\n",
    "print()\n",
    "print('nP:', d['nP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that our model outputted `[2, 15, 16]` as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:25:56.524424Z",
     "start_time": "2020-10-29T08:25:56.516450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: [2, 15, 16]\n",
      "\n",
      "Output tokens: ['*', (0,), (1,)]\n",
      "\n",
      "Substituting nP into output tokens: ['*', '30', '4']\n",
      "\n",
      "Evaluation: 120.0\n"
     ]
    }
   ],
   "source": [
    "pred = [2, 15, 16]\n",
    "print('Model output:', pred)\n",
    "print()\n",
    "out_tokens = [out_vocab.idx2token[x] for x in pred]\n",
    "print('Output tokens:', out_tokens)\n",
    "print()\n",
    "out_tokens = sub_nP(out_tokens, d['nP'])\n",
    "print('Substituting nP into output tokens:', out_tokens)\n",
    "print()\n",
    "print('Evaluation:', evaluate_prefix_expression(out_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we evaluate our model's prediction to the ground-truth output, we compare both the predicted expression to the ground-truth expression (Test equation accuracy) and the predicted value to the ground-truth value (Test value accuracy)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
